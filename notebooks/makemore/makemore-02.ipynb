{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "61c09433-826a-488e-bea9-0cac0fc9dcd6",
      "metadata": {
        "id": "61c09433-826a-488e-bea9-0cac0fc9dcd6"
      },
      "source": [
        "> **In this notebook, I have built a simple multilayer perceptron (MLP) from scratch. I took inspiration from the Neural Probabilistic Language Model (NPLM) paper, which introduced the idea of using neural networks to learn distributed representations of words and predict the next word in a sequence.The notebook covers:**\n",
        "\n",
        "```python\n",
        "# Implementing the MLP architecture for character-level language modeling.\n",
        "# Initializing and training the model on a small dataset.\n",
        "# Experimenting with hyperparameters such as learning rate and model size.\n",
        "# Evaluating training and validation loss.\n",
        "# Observing the effects of overfitting and underfitting.\n",
        "```\n",
        "> This hands-on implementation deepens understanding of how neural networks learn and generalize from data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a8ecaa5e-2f89-47eb-b44d-e004bba3adac",
      "metadata": {
        "id": "a8ecaa5e-2f89-47eb-b44d-e004bba3adac"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "aa8f8005-eb89-4b7b-8d60-bb02fe0227bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa8f8005-eb89-4b7b-8d60-bb02fe0227bd",
        "outputId": "7880831a-e1c1-43aa-c43b-31a16480b36e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['victoria', 'madison', 'luna', 'grace', 'chloe'] \n",
            "[ Num. of words]: [32033]\n"
          ]
        }
      ],
      "source": [
        "# read in all the words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "print(words[20:25] ,'\\n[ Num. of words]:',[len(words)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "90e30ae5-e743-43aa-905e-889f7a67f1e2",
      "metadata": {
        "id": "90e30ae5-e743-43aa-905e-889f7a67f1e2"
      },
      "outputs": [],
      "source": [
        "# build vocabulary of characters and map to int.\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fb65979f-3d9f-4a34-b8cc-8a8bf50af534",
      "metadata": {
        "id": "fb65979f-3d9f-4a34-b8cc-8a8bf50af534"
      },
      "outputs": [],
      "source": [
        "# build the dataset\n",
        "block_size = 3 # how many characters do we take to predict the next one?\n",
        "X, Y = [], []\n",
        "for w in words[:5]:\n",
        "  context = [0] * block_size\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "    context = context[1:] + [ix] # aaghe badho\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a08fb3d9-6bea-4067-bec6-51540873fb53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a08fb3d9-6bea-4067-bec6-51540873fb53",
        "outputId": "b5f2c8ea-9921-416f-fa27-32f66a36afd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6e569265-298a-4aba-8f66-574d8f0005d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e569265-298a-4aba-8f66-574d8f0005d3",
        "outputId": "8acb386d-b22c-472c-dd9a-89b41cfa0122"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "C = torch.randn((27, 2)) # token embedding\n",
        "emb = C[X] ; emb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1ac7b61a-3723-4a3c-94f4-71da19ee5643",
      "metadata": {
        "id": "1ac7b61a-3723-4a3c-94f4-71da19ee5643"
      },
      "outputs": [],
      "source": [
        "W1 = torch.randn((6, 100)) # 6 inputs (3 chars -> 2 vals) => 100 neurons\n",
        "b1 = torch.randn(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4be4d021-7120-43a8-a306-f078bcae059c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4be4d021-7120-43a8-a306-f078bcae059c",
        "outputId": "5b685b3f-09da-40e3-da88-956a41b1c6e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5543,  1.6604,  0.5543,  1.6604,  0.5543,  1.6604],\n",
              "        [ 0.5543,  1.6604,  0.5543,  1.6604, -0.2901, -1.5833],\n",
              "        [ 0.5543,  1.6604, -0.2901, -1.5833,  1.3519,  0.3837],\n",
              "        [-0.2901, -1.5833,  1.3519,  0.3837,  1.3519,  0.3837],\n",
              "        [ 1.3519,  0.3837,  1.3519,  0.3837, -0.6418,  1.0960],\n",
              "        [ 0.5543,  1.6604,  0.5543,  1.6604,  0.5543,  1.6604],\n",
              "        [ 0.5543,  1.6604,  0.5543,  1.6604, -1.0759,  2.3301],\n",
              "        [ 0.5543,  1.6604, -1.0759,  2.3301,  0.5395, -2.2043],\n",
              "        [-1.0759,  2.3301,  0.5395, -2.2043, -1.0781, -0.1733],\n",
              "        [ 0.5395, -2.2043, -1.0781, -0.1733,  0.5595, -0.2312],\n",
              "        [-1.0781, -0.1733,  0.5595, -0.2312, -1.0781, -0.1733],\n",
              "        [ 0.5595, -0.2312, -1.0781, -0.1733, -0.6418,  1.0960],\n",
              "        [ 0.5543,  1.6604,  0.5543,  1.6604,  0.5543,  1.6604],\n",
              "        [ 0.5543,  1.6604,  0.5543,  1.6604, -0.6418,  1.0960],\n",
              "        [ 0.5543,  1.6604, -0.6418,  1.0960,  0.5595, -0.2312],\n",
              "        [-0.6418,  1.0960,  0.5595, -0.2312, -0.6418,  1.0960],\n",
              "        [ 0.5543,  1.6604,  0.5543,  1.6604,  0.5543,  1.6604],\n",
              "        [ 0.5543,  1.6604,  0.5543,  1.6604, -1.0781, -0.1733],\n",
              "        [ 0.5543,  1.6604, -1.0781, -0.1733,  0.5629,  0.9092],\n",
              "        [-1.0781, -0.1733,  0.5629,  0.9092, -0.6418,  1.0960],\n",
              "        [ 0.5629,  0.9092, -0.6418,  1.0960, -1.2375,  0.3694],\n",
              "        [-0.6418,  1.0960, -1.2375,  0.3694, -0.2901, -1.5833],\n",
              "        [-1.2375,  0.3694, -0.2901, -1.5833,  0.5395, -2.2043],\n",
              "        [-0.2901, -1.5833,  0.5395, -2.2043,  0.5395, -2.2043],\n",
              "        [ 0.5395, -2.2043,  0.5395, -2.2043, -0.6418,  1.0960],\n",
              "        [ 0.5543,  1.6604,  0.5543,  1.6604,  0.5543,  1.6604],\n",
              "        [ 0.5543,  1.6604,  0.5543,  1.6604,  0.5629,  0.9092],\n",
              "        [ 0.5543,  1.6604,  0.5629,  0.9092, -1.0759,  2.3301],\n",
              "        [ 0.5629,  0.9092, -1.0759,  2.3301, -0.6625,  0.0618],\n",
              "        [-1.0759,  2.3301, -0.6625,  0.0618,  2.7881,  0.3225],\n",
              "        [-0.6625,  0.0618,  2.7881,  0.3225, -1.0781, -0.1733],\n",
              "        [ 2.7881,  0.3225, -1.0781, -0.1733, -0.6418,  1.0960]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "emb.view(-1,6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a3408e89-a634-4b10-a0dc-da1cb9484b0b",
      "metadata": {
        "id": "a3408e89-a634-4b10-a0dc-da1cb9484b0b"
      },
      "outputs": [],
      "source": [
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # layer 1 o/p vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "15759ba0-438d-4d73-a4e5-d14fec2a4036",
      "metadata": {
        "id": "15759ba0-438d-4d73-a4e5-d14fec2a4036"
      },
      "outputs": [],
      "source": [
        "# sigmoid function weights and bias => i/p 100 vals from layer 1 & o/p 27 probs for 27 chars\n",
        "W2 = torch.randn((100, 27))\n",
        "b2 = torch.randn(27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d9a338d2-1ce2-4eb3-85da-a6580418b2b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9a338d2-1ce2-4eb3-85da-a6580418b2b6",
        "outputId": "61b9ac07-db20-492a-9615-3d8bbc21c629"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "logits = h @ W2 + b2\n",
        "counts = logits.exp()\n",
        "prob = counts / counts.sum(1, keepdims=True)\n",
        "prob.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ae343e99-8a45-44f8-9420-687adb658275",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae343e99-8a45-44f8-9420-687adb658275",
        "outputId": "c323d846-fc7e-4e1a-d78a-55fbcbd3d931"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(21.5245)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "loss = -prob[torch.arange(32), Y].log().mean()\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d7835a04-ddb0-461e-aa9c-9d1b37994ae1",
      "metadata": {
        "id": "d7835a04-ddb0-461e-aa9c-9d1b37994ae1"
      },
      "outputs": [],
      "source": [
        "# funtion for building complete dataset for splitting train , val, test data\n",
        "block_size = 3\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix]\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e8fcd2bb-fc51-4296-85d2-54ed66d3d447",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8fcd2bb-fc51-4296-85d2-54ed66d3d447",
        "outputId": "31bb6750-b3b8-4aa8-c8eb-a0d7ea12b6f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words)) # 80 %\n",
        "n2 = int(0.9*len(words)) # 90 %\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1]) # training data\n",
        "Xdev, Ydev = build_dataset(words[n1:n2]) # validation data\n",
        "Xte, Yte = build_dataset(words[n2:]) # testing data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6981a142-c78a-45d9-a4d5-758164c28a32",
      "metadata": {
        "id": "6981a142-c78a-45d9-a4d5-758164c28a32"
      },
      "source": [
        "> **:)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "d6582eb2-2380-44ed-8ad1-fe959ad3fc65",
      "metadata": {
        "id": "d6582eb2-2380-44ed-8ad1-fe959ad3fc65"
      },
      "outputs": [],
      "source": [
        "# parameters for better nn\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,10), generator=g)\n",
        "W1 = torch.randn((30,200), generator=g)\n",
        "b1 = torch.randn(200 , generator=g)\n",
        "W2 = torch.randn((200,27), generator=g)\n",
        "b2 = torch.randn(27 , generator=g)\n",
        "parameters=[C , W1 , b1 , W2 ,b2 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "a69ea41c-f4a6-4446-960b-cbc1685cd2cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a69ea41c-f4a6-4446-960b-cbc1685cd2cb",
        "outputId": "17523b1c-dbfe-430c-b284-cb0e0db7a933"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11897"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "sum(p.nelement()  for p in parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "d87d2e37-d6a3-44bc-a474-b10fcf0feece",
      "metadata": {
        "id": "d87d2e37-d6a3-44bc-a474-b10fcf0feece"
      },
      "outputs": [],
      "source": [
        "for p in parameters:\n",
        "    p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "36c93f8e-94c8-4df4-a047-6f75489f3b48",
      "metadata": {
        "id": "36c93f8e-94c8-4df4-a047-6f75489f3b48"
      },
      "outputs": [],
      "source": [
        "# learning rate Sweep\n",
        "lre = torch.linspace(-3, 0, 100000)\n",
        "lrs = 10**lre\n",
        "lri = [] ; lossi = []; stepi = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "6602a6f7-6470-4108-a1b7-c1f1bcae48b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6602a6f7-6470-4108-a1b7-c1f1bcae48b5",
        "outputId": "dcbecb6d-4bca-471b-dc3d-d9b88d1e3a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.740038275718689\n"
          ]
        }
      ],
      "source": [
        "for i in range(10000):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (32,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 10)\n",
        "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 200)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "  #print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "    loss.backward(retain_graph=True)\n",
        "  # update lr\n",
        "  lr = 0.01\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xtr] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE1pf0zErEV-",
        "outputId": "7e1910b1-18b4-4f9a-c42e-b726deb9674a"
      },
      "id": "ZE1pf0zErEV-",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2545, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "54de42bd-affc-47f7-a2db-029e71448147",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54de42bd-affc-47f7-a2db-029e71448147",
        "outputId": "294b0878-2a23-4090-f451-66964c0210cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2689, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "emb = C[Xdev] # (32, 3, 2)\n",
        "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
        "logits = h @ W2 + b2 # (32, 27)\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "15d07d94-73cb-474e-8134-d6f5017143dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15d07d94-73cb-474e-8134-d6f5017143dc",
        "outputId": "13d6b9a0-e70d-4a7a-f4ce-b6822e5f31a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "context = [0] * block_size\n",
        "C[torch.tensor([context])].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "94c1984d-1232-49dd-9f2d-ad6697c0fe63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94c1984d-1232-49dd-9f2d-ad6697c0fe63",
        "outputId": "8951d25d-7416-48b6-e0d1-6f0fd00bab7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mora.\n",
            "kmyan.\n",
            "keel.\n",
            "nah.\n",
            "yal.\n",
            "rethan.\n",
            "ejd.\n",
            "leg.\n",
            "azelyn.\n",
            "elii.\n",
            "saylona.\n",
            "edeiseananas.\n",
            "kayzios.\n",
            "kalin.\n",
            "sadbergahiriel.\n",
            "kinie.\n",
            "jelilanterian.\n",
            "brey.\n",
            "dariyah.\n",
            "fael.\n"
          ]
        }
      ],
      "source": [
        "# generate sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "    print(''.join(itos[i] for i in out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb93298c-3c48-43c2-bf05-2b4663604bcf",
      "metadata": {
        "id": "eb93298c-3c48-43c2-bf05-2b4663604bcf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}